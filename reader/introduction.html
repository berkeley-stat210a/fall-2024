<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Course introduction</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-B8G2041HSB"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-B8G2041HSB', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../assets/styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../reader/introduction.html">Course Reader</a></li><li class="breadcrumb-item"><a href="../reader/introduction.html">Course introduction</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../assets/stat_bear.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Stat 210a</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/berkeley-stat210a/fall-2024" rel="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home / Schedule</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Course Logistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../faq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Frequently Asked Questions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../syllabus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Syllabus</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../calendar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Calendar</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Course Materials</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../handwritten-notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Handwritten notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../homework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../old-exams.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Old exams</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Course Reader</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/introduction.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Course introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability as a measure</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistical decision theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/exponential-families.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exponential Families</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/sufficiency.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sufficiency</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/completeness.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Completeness, Ancillarity, and Basu’s Theorem</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/unbiased-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unbiased Estimation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../license.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">License</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#about-stat-210a" id="toc-about-stat-210a" class="nav-link active" data-scroll-target="#about-stat-210a">About Stat 210A</a></li>
  <li><a href="#deductive-vs-inductive-reasoning" id="toc-deductive-vs-inductive-reasoning" class="nav-link" data-scroll-target="#deductive-vs-inductive-reasoning">Deductive vs inductive reasoning</a></li>
  <li><a href="#the-problem-of-induction" id="toc-the-problem-of-induction" class="nav-link" data-scroll-target="#the-problem-of-induction">The problem of induction</a></li>
  <li><a href="#statistical-evasions-in-practice-coin-flipping" id="toc-statistical-evasions-in-practice-coin-flipping" class="nav-link" data-scroll-target="#statistical-evasions-in-practice-coin-flipping">Statistical evasions in practice: coin flipping</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Course introduction</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p><span class="math display">\[
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\td}{\,\textrm{d}}
\newcommand{\simiid}{\stackrel{\textrm{i.i.d.}}{\sim}}
\newcommand{\eqas}{\stackrel{\textrm{a.s.}}{=}}
\newcommand{\eqPas}{\stackrel{\cP\textrm{-a.s.}}{=}}
\newcommand{\eqmuas}{\stackrel{\mu\textrm{-a.s.}}{=}}
\newcommand{\eqD}{\stackrel{D}{=}}
\newcommand{\indep}{\perp\!\!\!\!\perp}
\DeclareMathOperator*{\minz}{minimize\;}
\newcommand{\Var}{\textnormal{Var}}
\newcommand{\Cov}{\textnormal{Cov}}
\newcommand{\Corr}{\textnormal{Corr}}
\]</span></p>
<section id="about-stat-210a" class="level2">
<h2 class="anchored" data-anchor-id="about-stat-210a">About Stat 210A</h2>
<section id="what-is-the-theory-of-statistics" class="level4">
<h4 class="anchored" data-anchor-id="what-is-the-theory-of-statistics">What is the theory of statistics?</h4>
<p>Statistics is the study of methods that use data to understand the world. Statistical methods are used throughout the natural and social sciences, in machine learning and artificial intelligence, and in engineering. Despite the ubiquitous use of statistics, its practitioners are perpetually accused of not actually understanding what they are doing. Statistics theory is, broadly speaking, about trying to understand what we are doing when we use statistical methods.</p>
<p>While there are many possible ways to analyze data, most (but certainly not all) statistical methods are based on <strong>statistical modeling:</strong> treating the data as a realization of some <strong>random</strong> data-generating process with attributes, usually called <strong>parameters</strong><em>,</em> that are <em>a priori</em> unknown. The goal of the <strong>analyst</strong>, then, is to use the data to draw accurate inferences about these parameters and/or to make accurate predictions about future data. If the modeling has been done well (a very big “if”) then these unknown parameters will correspond well to whatever real-world questions initially motivated the analysis. Applied statistics courses like Stat 215A and B concern questions about how to ensure that the statistical modeling exercise successfully captures something interesting about reality.</p>
<p>In this course we will instead focus on how the analyst can use the data most effectively within the context of a given mathematical setup. We will discuss the structure of statistical models, how to evaluate the quality of a statistical method, how to design good methods for new settings, and the philosophy of Bayesian vs frequentist modeling frameworks. We will cover estimation, confidence intervals, and hypothesis testing, in parametric and nonparametric methods, in finite samples and asymptotic regimes.</p>
</section>
<section id="relationship-of-stat-210a-to-other-berkeley-courses" class="level4">
<h4 class="anchored" data-anchor-id="relationship-of-stat-210a-to-other-berkeley-courses">Relationship of Stat 210A to other Berkeley courses</h4>
<p>Stat 210A focuses on <em>classical</em> statistical contexts: either inference in finite samples, or in fixed-dimensional asymptotic regimes. Stat 210B (for which 210A is a prerequisite) is more technical and covers topics like empirical process theory and high-dimensional statistics.</p>
<p>Berkeley’s graduate course on Statistical Learning Theory (CS 281A / Stat 241A) is also very popular and has some overlap in its topics. Roughly speaking, it is more tilted toward “machine learning”: it spends more time on topics in predictive modeling (i.e.&nbsp;classification and regression, which are covered in Stat 215A), optimization, and signal processing, but spends less time on inferential questions and (I believe) does not cover topics like hypothesis testing, confidence intervals, and causal inference. Both courses cover estimation and exponential families.</p>
</section>
</section>
<section id="deductive-vs-inductive-reasoning" class="level2">
<h2 class="anchored" data-anchor-id="deductive-vs-inductive-reasoning">Deductive vs inductive reasoning</h2>
<section id="deductive-reasoning" class="level4">
<h4 class="anchored" data-anchor-id="deductive-reasoning">Deductive reasoning</h4>
<p>Most mathematics courses are entirely concerned with <strong>deductive reasoning</strong>: drawing conclusions that follow logically from premises. For example:</p>
<ol type="1">
<li><p>All real, symmetric matrices have real eigenvalues.</p></li>
<li><p><span class="math inline">\(A\)</span> is a real, symmetric matrix.</p></li>
<li><p><em>Therefore,</em> <span class="math inline">\(A\)</span> has real eigenvalues.</p></li>
</ol>
<p>Deductive reasoning comes up in everyday life, for example</p>
<ol type="1">
<li><p>No one in my daughter’s preschool class has a nut allergy.</p></li>
<li><p>Zoe is in my daughter’s preschool class.</p></li>
<li><p><em>Therefore</em>, Zoe is not allergic to peanuts.</p></li>
</ol>
<p>This type of argument is <em>risk-free</em> in the sense that, as long as the premises are true, the conclusions must hold. Of course, the premises could be false: I might be confusing my neighbor Zoe with a different Zoe who is in my daughter’s class. But that is the only way my conclusion could be wrong.</p>
<p>Deductive arguments can involve statements about probability:</p>
<ol type="1">
<li>This die has six faces labeled 1, 2, 3, 4, 5, and 6.</li>
<li>If I roll it, it is equally likely to land on any face.</li>
<li><em>Therefore,</em> the chance of rolling a 4 is exactly 1/6.</li>
</ol>
<p>A probability course like <strong>Stat 205A</strong> is about statements like this.</p>
</section>
<section id="inductive-reasoning" class="level4">
<h4 class="anchored" data-anchor-id="inductive-reasoning">Inductive reasoning</h4>
<p>Statistics, on the other hand, is the mathematical science of <strong>inductive reasoning</strong>: reasoning from observations to make general claims about the world. Unlike deductive reasoning, such arguments are inherently <em>risky</em>: the conclusions we draw can be false even when the premises are correct.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note that <strong>inductive proofs</strong> in mathematics are not an example of inductive reasoning as we mean it here. Inductive proofs are really examples of deductive reasoning because they provide a logically valid argument (i.e.&nbsp;the inductive step) for extending the conclusion to the entire class of objects under study.</p>
</div>
</div>
<p>For example:</p>
<ol type="1">
<li>I ate a blueberry from the free sample tray at the supermarket.</li>
<li>It was ripe and delicious.</li>
<li><em>Therefore</em>, if I buy a carton of blueberries, they will <em>probably</em> be ripe and delicious.</li>
</ol>
<p>Here we have added the weasel word “probably” not to convey a rigorous quantitative statement about probability, but just to informally convey some uncertainty about the conclusion.</p>
<p>This example would be more persuasive if we had taken a sample randomly from the carton we planned on buying:</p>
<ol type="1">
<li>I ate five blueberries at random from the carton I intended to buy.</li>
<li>They were all ripe and delicious.</li>
<li><em>Therefore</em>, if I buy the carton, the rest of the blueberries will <em>probably</em> be ripe and delicious.</li>
</ol>
<p>Of course, we could still always be wrong: maybe there were only five good blueberries in the whole carton and we just happened to take those. But that is not very likely.</p>
<p>Scientists very often reason inductively. For example:</p>
<ol type="1">
<li><p>Water at 1atm of pressure has been observed to boil at 100°C every time it has been measured in the laboratory.</p></li>
<li><p><em>Therefore,</em> water at 1atm of pressure <em>probably</em> always boils at 100°C.</p></li>
</ol>
<p>Inductive reasoning is the basis of all of the empirical sciences.</p>
<p>We can also make inductive statements about probability:</p>
<ol type="1">
<li><p>I flipped this penny 1000 times and got 502 heads.</p></li>
<li><p><em>Therefore</em>, it <em>probably</em> has about a 50% chance of landing heads.</p></li>
</ol>
<p>For now, we’ll assume we know what it means for a penny to have a 50% chance of landing heads; something like: it’s physical properties give it an equal chance of landing heads or tails (and a negligible chance of landing on its side or flying off into space). Generally, there is some controversy among different camps of philosophers and statisticians about what probability means, but not too much when it comes to coin flips. We’ll discuss this more later in the semester.</p>
</section>
</section>
<section id="the-problem-of-induction" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-of-induction">The problem of induction</h2>
<section id="humes-problem-of-induction" class="level4">
<h4 class="anchored" data-anchor-id="humes-problem-of-induction">Hume’s problem of induction</h4>
<p>Unfortunately, inductive reasoning is not <em>valid</em> in the sense meant by logicians or mathematicians. It doesn’t matter how many times I’ve seen real symmetric matrices that had real eigenvalues. Without a proof, I can’t make the general claim. There are entertaining examples of patterns being unexpectedly violated in math, such as the <a href="https://en.wikipedia.org/wiki/Borwein_integral">Borwein Integral</a>:</p>
<p><span class="math display">\[
\begin{aligned}
\int_0^\infty \frac{\sin x}{x}\,dx &amp;= \frac{\pi}{2}\\[10pt]
\int_0^\infty \frac{\sin x}{x}\, \frac{\sin(x/3)}{x/3}\,dx &amp;= \frac{\pi}{2}\\[10pt]
\int_0^\infty \frac{\sin x}{x}\, \frac{\sin(x/3)}{x/3}\, \frac{\sin(x/5)}{x/5}\,dx &amp;= \frac{\pi}{2}\\[10pt]
&amp;\vdots\\[10pt]
\int_0^\infty \frac{\sin x}{x}\, \frac{\sin(x/3)}{x/3}\,\cdots\, \frac{\sin(x/13)}{x/13}\,dx &amp;= \frac{\pi}{2}\\[10pt]
\int_0^\infty \frac{\sin x}{x}\, \frac{\sin(x/3)}{x/3}\,\cdots\, \frac{\sin(x/15)}{x/15}\,dx &amp;= \frac{\pi}{2} - 2.31 \times 10^{-11}.
\end{aligned}
\]</span></p>
<p>Bertrand Russell also warned about how inductive inference can go awry in real life:</p>
<blockquote class="blockquote">
<p>Domestic animals expect food when they see the person who usually feeds them. We know that all these rather crude expectations of uniformity are liable to be misleading. The man who has fed the chicken every day throughout its life at last wrings its neck instead, showing that more refined views as to the uniformity of nature would have been useful to the chicken.</p>
</blockquote>
<p>David Hume’s work <em>A Treatise of Human Nature</em> (1739) first proposed the <strong>problem of induction</strong>, namely that inductive reasoning presumes — seemingly without justification — that yet-to-be-observed cases will be similar to observed cases. This presumption is sometimes called the <strong>uniformity principle</strong>, and it is difficult to see how we can justify it. We can’t justify it through a direct logical argument, because it’s not logically justified. We could justify it by past experience — for example, at a low enough level, physical properties of the world generally seem to be uniform across space and time — but that argument is circular! Just because the future has been like the past in the past, doesn’t mean that it will be like the past in the future.</p>
<p>Hume allowed that people have to reason inductively all the time, but he called it a “custom” or “habit” and challenged philosophers to justify it. Now almost 300 years later, there does not seem to have been a fully satisfactory answer; most philosophers of science (like Karl Popper, for example) admit that inductive reasoning is fallible, but think there are reasonable ways for scientists to deal with this.</p>
</section>
<section id="statistical-evasions-of-the-problem-of-induction" class="level4">
<h4 class="anchored" data-anchor-id="statistical-evasions-of-the-problem-of-induction">Statistical evasions of the problem of induction</h4>
<p>We seem to be in trouble if we are trying to build a mathematical science of inductive reasoning, when the first thing we know about induction is that it is not mathematically valid. Statisticians have two main ways of evading this problem, which lead to the two main mathematical frameworks for statistical inference:</p>
<p><strong>Evasion 1: Bayesian reasoning</strong>. Bayesians respond to Hume that, whatever our <em>a priori</em> beliefs are about the world, we at least know how to update them in the light of experience using the mathematics of conditional probability. Our prior beliefs may not ultimately be justified, but there is only one rational way to update them (note this is somewhat disputed). We may hope that after enough experience they will “wash out” and observers with different prior beliefs will eventually converge in their beliefs after seeing enough data. We will study Bayesian statistics in a few weeks.</p>
<p><strong>Evasion 2: Inductive behavior (frequentist statistics)</strong>. Another way of evading the problem is to design methods for inference whose fallibility can be quantified. As long as certain assumptions hold concerning the conditions under which the data were collected, we may be able to come up with methods that we can mathematically prove give correct conclusions with high probability.</p>
</section>
</section>
<section id="statistical-evasions-in-practice-coin-flipping" class="level2">
<h2 class="anchored" data-anchor-id="statistical-evasions-in-practice-coin-flipping">Statistical evasions in practice: coin flipping</h2>
<section id="are-coins-really-fair" class="level4">
<h4 class="anchored" data-anchor-id="are-coins-really-fair">Are coins really fair?</h4>
<p>Although physical randomizers like coins and dice seem to be the firmest ground on which we can build a theory of probability, recent work has made the surprising finding that most human flippers have a somewhat greater than 50% chance of seeing their coin land on the same side as it started, due to the physics of rotating objects. This was first hypothesized in a theoretical article by Diaconis, Holmes, and Montgomery in 2007, and confirmed in a large experiment by Bartos et al.&nbsp;(2023), in which 48 human coin flippers collectively flipped <span class="math inline">\(n=350,757\)</span> coins — finding, indeed, that <span class="math inline">\(178,079\)</span> (<span class="math inline">\(50.77\%\)</span>) of the coins landed on the same side as they started.</p>
<p>In fact, Bartos et al.&nbsp;collected a lot more data than this: each of the 48 flippers recorded the full sequence of all of their coin flips, including which type of coin they were using (coins minted in 46 different countries were used). All flippers even had to submit video of themselves flipping the coins. But the analysis in the next section will use only the summary statistic <span class="math inline">\(X = 178,079\)</span>, which records the number of flips that landed same-side-up.</p>
</section>
<section id="frequentist-analysis-in-the-binomial-model" class="level4">
<h4 class="anchored" data-anchor-id="frequentist-analysis-in-the-binomial-model">Frequentist analysis in the binomial model</h4>
<p>The data set is simple to analyze if we make two seemingly innocuous simplifying assumptions: first, that the flips were statistically independent, and second, that every flip had an equal probability, which we will call <span class="math inline">\(\theta\)</span>, of landing on the same side it started on. In that case, we can conclude (deductively) that the probability that <span class="math inline">\(x\)</span> out of the <span class="math inline">\(n\)</span> flips land on the same side is exactly <span class="math inline">\(\binom{n}{x} \theta^x(1-\theta)^{n-x}\)</span>, for the realizable values <span class="math inline">\(x=0,\ldots,n\)</span>.</p>
<p>If we accept these assumptions, we arrive at a one-parameter <strong>statistical model</strong> for the entire data set, called the <strong>binomial model</strong>. We abbreviate this by writing <span class="math inline">\(X \sim \text{Binom}(n,\theta)\)</span>. If DHM’s prediction was right and a same-side bias exists, then we should have <span class="math inline">\(\theta &gt; 0.5\)</span>; if they are wrong and the starting side makes no difference, we should have <span class="math inline">\(\theta = 0.5\)</span>.</p>
<p>Following the frequentist paradigm, we can estimate the parameter <span class="math inline">\(\theta\)</span> via the <strong>estimator</strong> <span class="math inline">\(\hat\theta = X/n\)</span>, in this case <span class="math inline">\(0.5077\)</span>. One thing we will prove in this class is that <span class="math inline">\(X/n\)</span> is the best estimator of <span class="math inline">\(\theta\)</span>, among all <strong>unbiased</strong> estimators, meaning all estimators for which <span class="math inline">\(\EE_\theta \hat\theta = \theta\)</span>, for all possible values of the parameter <span class="math inline">\(\theta \in [0,1]\)</span>. This is an example of inductive behavior: if we use the estimator <span class="math inline">\(X/n\)</span> to estimate <span class="math inline">\(\theta\)</span>, we will get the answer right on average, and our estimate will be as precise (on average) as it could possibly be, for any unbiased estimator. We can also say how variable our estimator is: its standard error (the term of art we use for the standard deviation of an estimator) is <span class="math inline">\(\sqrt{\theta(1-\theta)}/n\)</span>. Substituting our estimator <span class="math inline">\(\hat\theta\)</span> for the true value <span class="math inline">\(\theta\)</span>, we estimate that <span class="math inline">\(\hat\theta\)</span> is typically off by about <span class="math inline">\(0.00084\)</span>, so we have good reason to believe <span class="math inline">\(0.0577\)</span> is about that close to the true value of <span class="math inline">\(\theta\)</span>. But we can’t necessarily say that it was close in this experiment; we could have gotten unlucky.</p>
<p>Can we confidently conclude, <em>inductively</em>, that there is a same-side bias (<span class="math inline">\(\theta &gt; 0.5\)</span>)? Naturally, even if DHM were wrong and there were no same-side bias (<span class="math inline">\(\theta = 0.5\)</span>), we would expect <span class="math inline">\(X/n\)</span> to deviate somewhat from <span class="math inline">\(0.5\)</span> in any given experiment, just by random chance. Could it be that that is what happened in this experiment?</p>
<p>Frequentist analysis evades this question and substitutes another question in its place. Using the <code>R</code> function <code>binom.test</code>, we can test the null hypothesis that <span class="math inline">\(\theta = 0.5\)</span> and calculate a <span class="math inline">\(95\%\)</span> confidence interval for <span class="math inline">\(\theta\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.test</span>(<span class="at">x =</span> <span class="dv">178079</span>, <span class="at">n =</span> <span class="dv">350757</span>, <span class="at">p =</span> <span class="fl">0.5</span>, <span class="at">alternative =</span> <span class="st">"greater"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Exact binomial test

data:  178079 and 350757
number of successes = 178079, number of trials = 350757, p-value &lt;
2.2e-16
alternative hypothesis: true probability of success is greater than 0.5
95 percent confidence interval:
 0.5063091 1.0000000
sample estimates:
probability of success 
             0.5076991 </code></pre>
</div>
</div>
<p>The <span class="math inline">\(p\)</span>-value tells us the likelihood that we could observe as many same-side flips as we did, if <span class="math inline">\(\theta\)</span> really were <span class="math inline">\(0.5\)</span>. In this experiment the <span class="math inline">\(p\)</span>-value is so small (<span class="math inline">\(p &lt; 2.2\times 10^{-16}\)</span>) that <code>R</code> doesn’t bother to tell us its exact value. The probability involved in calculating the <span class="math inline">\(p\)</span>-value follows from our binomial assumptions, but most reasonable people would probably accept this as sufficient evidence to reject the null hypothesis; that is, to reach the inductive conclusion that <span class="math inline">\(\theta\)</span> is not really <span class="math inline">\(0.5\)</span>.</p>
<p>This is a risky conclusion! Even if we were so conservative as to reject the null hypothesis only when <span class="math inline">\(p &lt; 10^{-10}\)</span>, say, there would still be some chance of our making a mistake in any given experiment. But we have quantified how likely this is, and we can decide whether it is high enough to trouble us.</p>
<p>Beyond just knowing that a same-side bias exists, it is interesting to have some sense of how large it is. Using very similar logic to the hypothesis test, the <code>binom.test</code> function also returns a <span class="math inline">\(95\%\)</span> <strong>confidence interval</strong> <span class="math inline">\([50.6\%, 50.9\%]\)</span> for the parameter <span class="math inline">\(\theta\)</span>. We will explore how to construct confidence intervals later in the semester, but for now it is sufficient to know that the interval is defined so that it has at least a $95$ chance of covering (i.e., including) <span class="math inline">\(\theta\)</span> in any given experiment, no matter what value <span class="math inline">\(\theta\)</span> takes. This is another example of inductive behavior: in producing a confidence interval, we take a risk that the corresponding inductive conclusion “<span class="math inline">\(\theta\)</span> lies between <span class="math inline">\(0.056\)</span> and <span class="math inline">\(0.0509\)</span>” is wrong, but we are behaving in such a way that we can quantify and limit this risk.</p>
</section>
<section id="bayesian-analysis" class="level4">
<h4 class="anchored" data-anchor-id="bayesian-analysis">Bayesian analysis</h4>
<p>Another route we could take, if we have a more Bayesian bent, is to introduce another assumption about the distribution that <span class="math inline">\(\theta\)</span> has; for example, that <span class="math inline">\(\theta \sim \text{Unif}[0,1]\)</span>. This is a stronger assumption than we made before: in what sense does <span class="math inline">\(\theta\)</span> have this distribution? Compared with the other assumptions, it is very difficult to test: there is only one draw from the distribution of <span class="math inline">\(\theta\)</span>, and it is observed only indirectly through the coin flips. However, it turns out in this case not to matter much what prior we picked, in the sense that many other prior distributions would result in almost the same posterior distribution.</p>
<p>If we make this assumption about the distribution of <span class="math inline">\(\theta\)</span>, then we can directly calculate the conditional distribution after observing <span class="math inline">\(X = 178,079\)</span>. The posterior distribution for <span class="math inline">\(\theta\)</span> can be calculated analytically, giving probability density <span class="math display">\[
\theta \mid X = x \sim  \frac{(n + 1)!}{x!(n-x)!} \theta^x (1-\theta)^{n-x}, \quad \text{ for } \theta \in [0,1].
\]</span> This distribution is called the <strong>Beta distribution</strong> with parameters <span class="math inline">\(\alpha = x+1\)</span> and <span class="math inline">\(\beta = n-x+1\)</span>. Note that this expression is a probability density for the parameter <span class="math inline">\(\theta\)</span>, not the . Once we know the distribution of <span class="math inline">\(\theta\)</span> we can make claims about it: for example, after seeing the data, there is only a <span class="math inline">\(3.8 \times 10^{-20}\)</span> chance that <span class="math inline">\(\theta \leq 0.5\)</span>. We can also calculate a <span class="math inline">\(95\%\)</span> Bayesian <strong>credible interval</strong>, which includes <span class="math inline">\(95\%\)</span> of the posterior probability mass. In this case, the interval is <span class="math inline">\([50.6\%, 50.9\%]\)</span>, coinciding with the frequentist confidence interval to several decimal points. The credible interval is making a stronger claim than the confidence interval: it is saying, <em>for this</em> <span class="math inline">\(\theta\)</span>, there is a <span class="math inline">\(95\%\)</span> chance that it falls in that range.</p>
</section>
<section id="questioning-the-binomial-model" class="level4">
<h4 class="anchored" data-anchor-id="questioning-the-binomial-model">Questioning the binomial model</h4>
<p>Bartos et al.&nbsp;stated in their paper that the binomial model is not quite correct: some human flippers had more same-side bias than others. We can modify the binomial model to allow for a different same-side probability <span class="math inline">\(\theta_i\)</span> for flipper <span class="math inline">\(i\)</span> over their <span class="math inline">\(n_i\)</span> coin flips (with <span class="math inline">\(\sum_i n_i = n\)</span>). If we retain the independence assumption, this leads to a more complex model where <span class="math inline">\(X_i \sim \text{Binom}(n_i,\theta_i)\)</span> independently for each <span class="math inline">\(i = 1, \ldots, 48\)</span>.</p>
<p>There was also evidence that the flippers were improving over time. If we want to accommodate this information we can expand the model yet again, to allow <span class="math inline">\(X_{i,t} \sim \text{Bernoulli}(\theta_{i,t})\)</span> independently for <span class="math inline">\(i = 1,\ldots,48\)</span> and <span class="math inline">\(t = 1,\ldots, n_i\)</span>. We might add the constraint that for each <span class="math inline">\(i\)</span>, we have <span class="math inline">\(\theta_{i,1} \geq \theta_{i,2} \geq \cdots \geq \theta_{i,n_i}\)</span>. With <span class="math inline">\(n = 350,757\)</span> parameters, one for every data point, this is effectively a nonparametric model. We will return to these models in future lectures.</p>
</section>
<section id="questions-well-return-to" class="level4">
<h4 class="anchored" data-anchor-id="questions-well-return-to">Questions we’ll return to</h4>
<p>This example is complex enough to give us a glimpse of some of the questions we’ll be interested in throughout the semester:</p>
<ol type="1">
<li><p><strong>Bayesian vs frequentist frameworks:</strong> What are the pros and cons of each? Where does the prior come from, and how important is our choice of prior for the analysis?</p></li>
<li><p><strong>Sufficiency:</strong> The first binomial analysis summarized the data as just the number <span class="math inline">\(X\)</span> of total same-side flips, even though we have a lot more data than that (for one thing, we know the full sequence of flips for each flipper). As we’ll see, under the binomial model we lose nothing by summarizing the full data set by <span class="math inline">\(X\)</span> alone and forgetting everything else about it. What is it about the structure of the binomial model that makes this a complete summary?</p></li>
<li><p><strong>Estimation:</strong> What is a good way to estimate the parameters in each of these models? In the second model with a different <span class="math inline">\(\theta_i\)</span> for each flipper, how can / should our estimate for one flipper be informed by the data from the other <span class="math inline">\(47\)</span> flippers? In the third model, if we want to introduce a parametric functional form for the way <span class="math inline">\(\theta_{i,t}\)</span> changes with time, what would be a good model and how should we estimate it?</p></li>
<li><p><strong>Testing:</strong> In the basic binomial model, if we want to conclude with as much confidence as we can that there is some same-side bias, we might want to test the hypothesis <span class="math inline">\(H_0:\;\theta \leq 0.5\)</span> vs <span class="math inline">\(H_1: \;\theta &gt; 0.5\)</span>. As it turns out, there is a unique best way to do this: reject when <span class="math inline">\(X\)</span> is large. In the second model, we might want to test whether we really need different <span class="math inline">\(\theta_i\)</span> values for the different flippers, by testing <span class="math inline">\(H_0:\; \theta_1=\theta_2=\cdots=\theta_{48}\)</span> against <span class="math inline">\(H_1:\; \text{not all } \theta_i \text{ are equal}\)</span>. That is, we test the null that the first model was adequate. This is a more complex testing problem for two reasons: our null hypothesis has a nuisance parameter, which may affect the null distribution of any test statistic; and our <span class="math inline">\(48\)</span>-dimensional alternative distribution can vary from the <span class="math inline">\(1\)</span>-dimensional null model in many, many different directions. As we’ll see, it can matter a lot which alternative directions are prioritized by the test we select.</p></li>
<li><p><strong>Asymptotics:</strong> In analyzing this data set we will never actually calculate anything like <span class="math inline">\(350,757!\)</span> even though that quantity appears in the equations. In practice we replace the binomial model with an appropriate Normal model, in this case <span class="math inline">\(X \sim \cN(n\theta, n\theta(1-\theta))\)</span>, and do the calculations with respect to that model. The normal approximation here is an obvious consequence of the central limit theorem, but we can make similar approximations in a lot of other problems where it is not so obvious <em>a priori</em> that this would be possible.</p></li>
</ol>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>