<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>The James-Stein Estimator</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-B8G2041HSB"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-B8G2041HSB', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../assets/styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">
      Stat 210a
      </li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../assets/stat_bear.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Stat 210a</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/berkeley-stat210a/fall-2024" rel="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home / Schedule</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Course Logistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../faq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Frequently Asked Questions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../syllabus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Syllabus</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../calendar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Calendar</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Course Materials</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../handwritten-notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Handwritten notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../homework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Homework</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../old-exams.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Old exams</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Course Reader</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistical models and estimation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/exponential-families.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exponential Families</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/sufficiency.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sufficiency</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/completeness.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Completeness, Ancillarity, and Basu’s Theorem</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reader/unbiased-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unbiased Estimation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../license.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">License</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#gaussian-sequence-model" id="toc-gaussian-sequence-model" class="nav-link active" data-scroll-target="#gaussian-sequence-model"><span class="header-section-number">1</span> Gaussian sequence model</a>
  <ul class="collapse">
  <li><a href="#bayes-estimators" id="toc-bayes-estimators" class="nav-link" data-scroll-target="#bayes-estimators"><span class="header-section-number">1.1</span> Bayes estimators</a></li>
  <li><a href="#james-stein-paradox" id="toc-james-stein-paradox" class="nav-link" data-scroll-target="#james-stein-paradox"><span class="header-section-number">1.2</span> James-Stein Paradox</a></li>
  <li><a href="#linear-shrinkage-estimators" id="toc-linear-shrinkage-estimators" class="nav-link" data-scroll-target="#linear-shrinkage-estimators"><span class="header-section-number">1.3</span> Linear shrinkage estimators</a></li>
  </ul></li>
  <li><a href="#steins-unbiased-risk-estimator" id="toc-steins-unbiased-risk-estimator" class="nav-link" data-scroll-target="#steins-unbiased-risk-estimator"><span class="header-section-number">2</span> Stein’s Unbiased Risk Estimator</a>
  <ul class="collapse">
  <li><a href="#steins-lemma" id="toc-steins-lemma" class="nav-link" data-scroll-target="#steins-lemma"><span class="header-section-number">2.1</span> Stein’s Lemma</a></li>
  <li><a href="#steins-unbaised-risk-estimator-sure" id="toc-steins-unbaised-risk-estimator-sure" class="nav-link" data-scroll-target="#steins-unbaised-risk-estimator-sure"><span class="header-section-number">2.2</span> Stein’s unbaised risk estimator (SURE)</a></li>
  <li><a href="#example-shrinking-toward-overlinex" id="toc-example-shrinking-toward-overlinex" class="nav-link" data-scroll-target="#example-shrinking-toward-overlinex"><span class="header-section-number">2.3</span> Example: shrinking toward <span class="math inline">\(\overline{X}\)</span></a></li>
  </ul></li>
  <li><a href="#risk-of-the-james-stein-estimator" id="toc-risk-of-the-james-stein-estimator" class="nav-link" data-scroll-target="#risk-of-the-james-stein-estimator"><span class="header-section-number">3</span> Risk of the James-Stein estimator</a>
  <ul class="collapse">
  <li><a href="#final-thoughts" id="toc-final-thoughts" class="nav-link" data-scroll-target="#final-thoughts"><span class="header-section-number">3.1</span> Final thoughts</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">The James-Stein Estimator</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p><span class="math display">\[
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\td}{\,\textrm{d}}
\newcommand{\simiid}{\stackrel{\textrm{i.i.d.}}{\sim}}
\newcommand{\eqas}{\stackrel{\textrm{a.s.}}{=}}
\newcommand{\eqPas}{\stackrel{\cP\textrm{-a.s.}}{=}}
\newcommand{\eqmuas}{\stackrel{\mu\textrm{-a.s.}}{=}}
\newcommand{\eqD}{\stackrel{D}{=}}
\newcommand{\indep}{\perp\!\!\!\!\perp}
\DeclareMathOperator*{\minz}{minimize\;}
\DeclareMathOperator*{\maxz}{minimize\;}
\DeclareMathOperator*{\argmin}{argmin\;}
\DeclareMathOperator*{\argmax}{argmax\;}
\newcommand{\Var}{\textnormal{Var}}
\newcommand{\Cov}{\textnormal{Cov}}
\newcommand{\Corr}{\textnormal{Corr}}
\]</span></p>
<section id="gaussian-sequence-model" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="gaussian-sequence-model"><span class="header-section-number">1</span> Gaussian sequence model</h2>
<p>Recall that we have discussed a variety of estimators for <span class="math inline">\(\theta \in \RR^d\)</span> in the <em>Gaussian sequence model</em></p>
<p><span class="math display">\[X \sim N_d(\theta, I_d)\]</span></p>
<p>Note that this model is somewhat more general than it appears. If <span class="math inline">\(X_1,\ldots,X_n \simiid N_d(\theta, \sigma^2 I_d)\)</span> for known <span class="math inline">\(\sigma^2&gt; 0\)</span>, we could make a sufficiency reduction to obtain</p>
<p><span class="math display">\[Z = \frac{1}{\sigma\sqrt{n}} \sum_i X_i \sim N_d(\theta, I_d).\]</span> For simplicity we will discuss the ``vanilla’’ version here, but we can always translate our results to the more general setting via this transformation.</p>
<p>We’ll generally assume in what follows that the loss we care about is the squared error loss, summed over the coordinates: <span class="math display">\[L(\theta, d) =
\|\delta(X) - \theta\|^2 = \sum_j (\delta_j(X) - \theta_j)^2\]</span></p>
<p>The most obvious estimator is <span class="math inline">\(\delta_0(X) = X\)</span> itself, which we could justify in a variety of ways: we’ve shown that it is the UMVU estimator for <span class="math inline">\(\theta\)</span> and also the objective Bayes estimator, since the flat prior on <span class="math inline">\(\theta\)</span> coincides with the Jeffreys prior (as it does for any location model). It also happens to be the maximum likelihood estimator (MLE), which we’ll discuss later in the course.</p>
<section id="bayes-estimators" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="bayes-estimators"><span class="header-section-number">1.1</span> Bayes estimators</h3>
<p>If we introduce the Bayesian prior <span class="math inline">\(\theta_i \simiid N(0,\tau^2)\)</span> then we have seen that we arrive at the Bayes estimator <span class="math inline">\(\frac{\tau^2}{1+\tau^2}X\)</span>.</p>
<p>We can think of this as a tuning parameter for a generic <em>linear shrinkage estimator</em> <span class="math display">\[\delta_\zeta(X) = (1-\zeta)X,\]</span> where <span class="math inline">\(\zeta \in [0,1]\)</span> is in effect a tuning parameter we will call the <em>shrinkage parameter</em>. Taking <span class="math inline">\(\zeta = 0\)</span> corresponds to using <span class="math inline">\(X\)</span> as our estimator for <span class="math inline">\(\theta\)</span>, and taking <span class="math inline">\(\zeta = 1/(1+\tau^2)\)</span> corresponds to the Bayes estimator where <span class="math inline">\(\tau^2\)</span> is known.</p>
<p>If we aren’t sure which <span class="math inline">\(\zeta\)</span> to use, for example because we have some <em>a priori</em> uncertainty about <span class="math inline">\(\tau^2\)</span>, we can try to estimate it from the data using hierarchical Bayes, which we’ve seen would give the final estimator <span class="math display">\[\delta(X) = (1 - \EE[\zeta \mid X]) X = \delta_{\hat\zeta_{\text{Bayes}}(X)}(X),\]</span> so we are in effect estimating <span class="math inline">\(\zeta\)</span> from the whole data set and then plugging it in as a data-adaptive tuning parameter.</p>
<p>The hierarchical Bayes estimator uses a Bayes estimator for <span class="math inline">\(\zeta\)</span>, but if we take an empirical Bayes approach we could try other estimators, such as the MLE or UMVU. If <span class="math inline">\(d \geq 3\)</span> then the UMVU estimator for <span class="math inline">\(\zeta\)</span> is <span class="math display">\[\hat{\zeta}_{\text{UMVU}}(X) = \frac{d-2}{\|X\|^2},\]</span> which we can verify using the identity <span class="math display">\[\EE[1/Y] = \frac{1}{d-2}, \quad \text{ if } Y \sim \chi_d^2 = \text{Gamma}(d/2, 2), \text{ for } d &gt; 2,\]</span> which is proved in the handwritten notes. Plugging in <span class="math inline">\(\hat\zeta_\text{UMVU}\)</span> results in an estimator called the <em>James-Stein</em> estimator, <span class="math display">\[ \delta_{\text{JS}}(X)= \left(1 - \frac{d-2}{\|X\|^2}\right)X = \delta_{\hat\zeta_{\text{UMVU}}}(X) \]</span></p>
</section>
<section id="james-stein-paradox" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="james-stein-paradox"><span class="header-section-number">1.2</span> James-Stein Paradox</h3>
<p>While the James-Stein estimator can be motivated as an empirical Bayes estimator, it is surprisingly good even without making any Bayesian assumptions at all.</p>
<p>For <span class="math inline">\(d \geq 3\)</span>, the estimator <span class="math inline">\(X\)</span> is actually <em>inadmissible</em> as an estimator of <span class="math inline">\(\theta\)</span> under squared error loss:</p>
<p><span class="math display">\[\text{MSE}(\theta, \delta_{JS}) &lt; \text{MSE}(\theta, X) \quad \text{ for all } \theta \in \mathbb{R}^d.\]</span></p>
<p>It is not surprising for a Bayes estimator to beat the UMVU estimator <em>an average</em> with respect to some prior, but this result holds for <em>every fixed value</em> of the parameter <span class="math inline">\(\theta\)</span>.</p>
<p>In fact, since there is nothing special about shrinking towards <span class="math inline">\(0\)</span>. We could use a version of the estimator that shrinks toward any other <span class="math inline">\(\theta_0 \in \RR^d\)</span>, i.e. <span class="math display">\[ \tilde delta(X) = \theta_0 + \left(1 - \frac{d-2}{\|X - \theta_0\|^2}\right) (X - \theta_0)\]</span>. This also dominates <span class="math inline">\(\delta_0\)</span> because it is just the James-Stein estimator we’d get if we made the substitution <span class="math display">\[Y = X - \theta_0 \sim N_d(\mu, I_d), \quad \text{ for } \mu = \theta - \theta_0.\]</span> The translation-invariance of the Gaussian location model means that the James-Stein estimator for <span class="math inline">\(\mu\)</span> using <span class="math inline">\(Y\)</span> also dominates the estimator <span class="math inline">\(\hat\mu_0(Y) = Y\)</span>, which corresponds to the estimator <span class="math inline">\(\delta_0(X) = \hat\mu_0 + \theta_0 = X\)</span> for <span class="math inline">\(\theta\)</span>.</p>
<p>This result was received as a shock in the 1950s when it first came out. It was regarded for a long time as a curiosity, but it was eventually understood to carry the deep implication that shrinkage makes sense, especially in higher-dimensional problems, even when we don’t have a Bayes justification for it.</p>
</section>
<section id="linear-shrinkage-estimators" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="linear-shrinkage-estimators"><span class="header-section-number">1.3</span> Linear shrinkage estimators</h3>
<p>Even without introducing a Bayesian prior for <span class="math inline">\(\theta\)</span>, we can motivate our linear shrinkage estimator purely from the perspective of trading a bit of bias for a reduction in variance.</p>
<p>We can start by calculating the MSE (considered as a purely frequentist risk function) for a single coordinate, using the bias-variance tradeoff: <span class="math display">\[
\begin{aligned}
\EE_\theta[(\theta - \delta_i(X))^2]
&amp;= (\theta_i - \EE_\theta (1-\zeta)X_i)^2 + \text{Var}_\theta (1-\zeta)X_i\\
&amp;= (\zeta\theta_i)^2 + (1-\zeta)^2
\end{aligned}
\]</span> Summing over the <span class="math inline">\(d\)</span> coordinates gives <span class="math display">\[\text{MSE}(\theta; \delta) = \zeta^2\|\theta\|^2 + d(1-\zeta)^2,\]</span> where the first term represents the squared bias and the second is the variance.</p>
<p>Note that the risk is a quadratic in <span class="math inline">\(\zeta\)</span> with positive second derivative, so we can minimize it by setting <span class="math display">\[0 = \frac{d}{d\zeta}\text{MSE}(\theta) = 2\zeta\|\theta\|^2 - 2(1-\zeta)d,\]</span> leading to <span class="math display">\[\zeta^*(\theta) = \frac{d}{d+\|\theta\|^2} = \frac{1}{1+\|\theta\|^2/d},\]</span> which looks remarkably similar to <span class="math inline">\(\frac{1}{1+\tau^2}\)</span>, which is the Bayes-optimal <span class="math inline">\(\zeta\)</span> under the Gaussian prior from the last section.</p>
<p>One thing to notice is that <span class="math inline">\(\zeta^*(\theta) &gt; 0\)</span>, so a small amount of shrinkage helps. But the correct amount of shrinkage depends on <span class="math inline">\(\|\theta\|^2\)</span>: if <span class="math inline">\(\|\theta\|^2 \to \infty\)</span>, the correct amount of shrinkage goes to <span class="math inline">\(0\)</span>, so any fixed <span class="math inline">\(\zeta\)</span> would overshoot for some <span class="math inline">\(\theta\)</span> parameters.</p>
<p>It turns out the James-Stein estimator manages to estimate the correct amount of shrinkage from the data, in such a way that we avoid overshooting most of the time, and thereby improve on the MSE for <em>any</em> <span class="math inline">\(\theta\)</span>.</p>
<p>To understand why, we need a general way to calculate the MSE for an estimator with an adaptive <span class="math inline">\(\hat\zeta(X)\)</span>. Stein’s unbiased risk estimator will give us that.</p>
</section>
</section>
<section id="steins-unbiased-risk-estimator" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="steins-unbiased-risk-estimator"><span class="header-section-number">2</span> Stein’s Unbiased Risk Estimator</h2>
<section id="steins-lemma" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="steins-lemma"><span class="header-section-number">2.1</span> Stein’s Lemma</h3>
<p>The first ingredient in finding the MSE of <span class="math inline">\(\delta_\text{JS}\)</span> is a lemma called <em>Stein’s Lemma</em>:</p>
<p><strong>Theorem (Stein’s lemma, univariate):</strong> Suppose <span class="math inline">\(X \sim N(\theta, \sigma^2)\)</span>, and that <span class="math inline">\(h:\; \RR \to \RR\)</span> is differentiable, with <span class="math inline">\(\EE|\dot{h}(X)| &lt; \infty\)</span>. Then we have <span class="math display">\[\Cov(X, h(X)) = \EE[(X-\theta)h(X)] = \sigma^2\EE[\dot{h}(X)].\]</span></p>
<p><em>Proof</em>:</p>
<p>Next, we will do the calculation for <span class="math inline">\(\theta = 0\)</span> and <span class="math inline">\(\sigma^2 = 1\)</span>. Then <span class="math display">\[\EE[Xh(X)] = \int_{-\infty}^\infty xh(x)\phi(x)\,dx = \int_{-\infty}^\infty \dot{h}(x)\phi(x)\,dx,\]</span> where we’ve used integration by parts: <span class="math display">\[\dot{\phi}(x) = \frac{d}{dx} \frac{1}{\sqrt{2\pi}}e^{-x^2/2} = -x \frac{1}{\sqrt{2\pi}}e^{-x^2/2} = -x\phi(x).\]</span> (A slightly more rigorous version is in the handwritten notes: we can assume wlog <span class="math inline">\(h(0) = 0\)</span> because otherwise we could center it by using <span class="math inline">\(k(X) = h(X) - h(0)\)</span>, which has the same covariance with <span class="math inline">\(X\)</span>. Then we can break up the integral into an integral from <span class="math inline">\(0\)</span> to <span class="math inline">\(\infty\)</span> and another from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(0\)</span>, and do integration by parts a bit more carefully for each.)</p>
<p>For more general <span class="math inline">\(\theta\)</span>, we can write <span class="math inline">\(X = \theta + \sigma Z\)</span>, where <span class="math inline">\(Z \sim N(0,1)\)</span>. Then applying the result for <span class="math inline">\(k(z) = h(\theta + \sigma z)\)</span>, we have</p>
<p><span class="math display">\[\EE[(X-\theta) h(X)] = \sigma\EE[Zh(\theta + \sigma Z)] = \sigma^2\EE[\dot{h}(\theta + \sigma Z)] = \sigma^2\EE[\dot{h}(X)],\]</span> giving the general result.</p>
<p>We will need the multivariate version of Stein’s lemma. For a function <span class="math inline">\(h:\; \RR^d \to \RR^d\)</span>, define the Jacobian matrix <span class="math inline">\(Dh \in \RR^{d\times d}\)</span> by <span class="math display">\[(Dh(x))_{ij} = \frac{\partial h_i}{\partial x_j}(x).\]</span></p>
<p>Define the <strong>Frobenius norm</strong> <span class="math inline">\(A \in \RR^{d\times d}\)</span> as <span class="math display">\[\|A\|_F = \left(\sum_{ij} A_{ij}^2\right)^{1/2}.\]</span></p>
<p>Now we can state our theorem:</p>
<p><strong>Theorem (Stein’s lemma, multivariate):</strong> Assume <span class="math inline">\(X \sim N_d(\theta; \sigma^2 I_d)\)</span>, and <span class="math inline">\(h:\;\RR^d \to \RR^d\)</span> is differentiable with <span class="math inline">\(\EE\|Dh(X)\|_F &lt; \infty\)</span>. Then <span class="math display">\[ \EE[(X-\theta)'h(X)] = \sigma^2 \EE \text{tr}(Dh(X)) = \sigma^2 \sum_i \EE \frac{\partial h_i}{\partial x_i} (X).\]</span></p>
<p><em>Proof:</em> The proof follows from the proof of the univariate version if we observe that the distribution of <span class="math inline">\(X_i\)</span> conditional on the other coordinates <span class="math inline">\(X_{-i}\)</span> is <span class="math inline">\(N(\theta, \sigma^2)\)</span>. Then we have <span class="math display">\[ \EE\left[(X_i - \theta_i)h_i(X) \mid X_{-i}\right]
= \sigma^2 \EE\left[\frac{\partial h_i}{\partial x_i}(X_i) \mid X_{-i} \right].\]</span> Taking expectations gives <span class="math display">\[ \EE\left[(X_i - \theta_i)h_i(X)\right]
= \sigma^2 \EE\left[\frac{\partial h_i}{\partial x_i}(X_i) \right],\]</span> and summing over <span class="math inline">\(i\)</span> gives the result.</p>
</section>
<section id="steins-unbaised-risk-estimator-sure" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="steins-unbaised-risk-estimator-sure"><span class="header-section-number">2.2</span> Stein’s unbaised risk estimator (SURE)</h3>
<p>We can obtain an unbiased estimator of the MSE for almost any differentiable estimator <span class="math inline">\(\delta(X)\)</span> in the Gaussian sequence model, if we apply Stein’s lemma to the function <span class="math inline">\(h(x) = x - \delta(x)\)</span>. We only need the derivative of <span class="math inline">\(h\)</span> to satisfy the condition of Stein’s lemma, which it does for most differentiable estimators.</p>
<p>Using the identity <span class="math inline">\(\|a - b\|^2 = \|a\|^2 + \|b\|^2 - 2a'b\)</span>, we have for <span class="math inline">\(h(x) = x - \delta(x)\)</span>, <span class="math display">\[
\begin{aligned}
\text{MSE}(\theta; \delta)
&amp;= \EE_\theta\|\delta(X) - \theta\|^2\\
&amp;= \EE_\theta\|X - h(X) - \theta\|^2\\
&amp;= \EE_\theta\|X - \theta\|^2 + \EE_\theta\|h(X)\|^2 - 2\EE_\theta \left[(X - \theta)'h(X)\right]\\
&amp;= \sigma^2 d + \EE_\theta\|h(X)\|^2 - 2\sigma^2 \EE_\theta \text{tr}(Dh(X)).
\end{aligned}
\]</span> Thus, if <span class="math inline">\(\sigma^2\)</span> is known, we obtain the unbiased estimator <span class="math display">\[ \widehat{\text{MSE}}(X) = \sigma^2 d +  \|h(X)\|^2 - 2 \sigma^2 \text{tr}(Dh(X)).\]</span></p>
</section>
<section id="example-shrinking-toward-overlinex" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="example-shrinking-toward-overlinex"><span class="header-section-number">2.3</span> Example: shrinking toward <span class="math inline">\(\overline{X}\)</span></h3>
<p>As an example, we can estimate the MSE of an estimator that shrinks <span class="math inline">\(X_i\)</span> partway toward the average estimate across the <span class="math inline">\(d\)</span> coordinates, <span class="math inline">\(\overline{X} = \frac{1}{d}\sum_i X_i\)</span>: <span class="math display">\[
\delta_i^\gamma(X) = (1-\gamma) X_i  + \gamma \overline{X}.
\]</span> We can think of this as making a bet that most of the <span class="math inline">\(\theta_i\)</span> values are close to <span class="math inline">\(\bar{\theta} = \frac{1}{d}\sum_i \theta_i\)</span>. Then <span class="math display">\[
h(X) = X - \delta^\gamma(X) = \gamma(X - \overline{X} 1_d),
\]</span> and <span class="math display">\[
Dh(X)_{ii} = \frac{\partial}{\partial X_i} \gamma(X_i - \overline{X}) = \gamma (1-1/d) \Rightarrow \text{tr}(Dh(X)) = (d-1)\gamma
\]</span> An unbiased estimator for the MSE of <span class="math inline">\(\delta^\gamma\)</span> is then <span class="math display">\[
\widehat{\text{MSE}}^\gamma(X) = \sigma^2 d +  \gamma^2(d-1)V^2 - 2(d-1) \gamma \sigma^2,
\]</span> where <span class="math inline">\(V^2 = \frac{1}{d-1}\sum_i (X_i-\overline{X})^2\)</span> is the sample variance. Take note that the <span class="math inline">\(X_i\)</span> values are not assumed to be i.i.d. here, since their means are generically different.</p>
<p>We can use this estimator in two different ways. The simplest way would be to calculate the actual MSE by taking the estimator’s expectation, which we know is the actual MSE of <span class="math inline">\(\delta^\gamma\)</span>. The only random variable is <span class="math inline">\(V^2\)</span>. Write <span class="math inline">\(X_i = \theta_i + Z_i\)</span> where <span class="math inline">\(Z_i \sim N(0,\sigma^2)\)</span>. Then we have <span class="math display">\[
\frac{1}{d-1}\sum_i\EE_\theta(X_i-\overline{X})^2 = \frac{1}{d-1}\sum_i (\theta_i - \bar{\theta})^2 + \frac{1}{d-1}\sum_i \EE(Z_i - \overline{Z})^2 = \beta^2 + \sigma^2,
\]</span> where <span class="math inline">\(\beta^2 = \frac{1}{d-1}\sum_i(\theta_i - \bar{\theta})^2\)</span> is the sample variance of the <span class="math inline">\(\theta_i\)</span> values. Plugging in this expectation and collecting terms, we obtain the MSE <span class="math display">\[
\text{MSE}^\gamma(\theta) = \EE_\theta\left[\widehat{\text{MSE}}^\gamma(X)\right] = \sigma^2 + (d-1)(1-\gamma)^2\sigma^2 + (d-1)\gamma^2\beta^2.
\]</span> We can solve for the optimal value <span class="math inline">\(\gamma^*(\beta) = \frac{\sigma^2}{\beta^2+\sigma^2}\)</span>, which unsurprisingly depends on <span class="math inline">\(\beta^2\)</span>. If <span class="math inline">\(\beta^2 = 0\)</span> then all <span class="math inline">\(\theta_i\)</span> values are equal so we should set <span class="math inline">\(\gamma = 1\)</span> (shrink fully to the sample mean), but if <span class="math inline">\(\beta^2 \gg \sigma^2\)</span> we should take <span class="math inline">\(\gamma \to 0\)</span> (shrink very little).</p>
<p>We could also choose <span class="math inline">\(\gamma\)</span> adaptively to minimize this estimator. That is, we could take <span class="math display">\[
\hat\gamma(X) = \argmin_\gamma \widehat{\text{MSE}}^\gamma(X) = \sigma^2/V^2,
\]</span> which we could think of as an estimator of <span class="math inline">\(\gamma^*(X)\)</span> since <span class="math inline">\(V^2\)</span> is unbiased for <span class="math inline">\(\beta^2+\sigma^2\)</span>. If we plug in <span class="math inline">\(\hat\gamma(X)\)</span> we get a new adaptive shrinkage estimator which is not the same as <span class="math inline">\(\delta^\gamma\)</span> for any fixed <span class="math inline">\(\gamma\)</span>, and we could use the same idea to calculate its MSE, if we wanted to.</p>
</section>
</section>
<section id="risk-of-the-james-stein-estimator" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="risk-of-the-james-stein-estimator"><span class="header-section-number">3</span> Risk of the James-Stein estimator</h2>
<p>We are now ready to calculate the risk of the James–Stein estimator <span class="math inline">\(\delta_{JS}(X) = \left(1 - \frac{d-2}{\|X\|^2}\right)X\)</span>. We can drop the assumption $^2 = $, under the assumption <span class="math inline">\(\sigma^2 = 1\)</span> (for general <span class="math inline">\(\sigma^2\)</span>, we should replace the numerator <span class="math inline">\(d-2\)</span> with <span class="math inline">\((d-2)\sigma^2\)</span>. Then ).</p>
<p>Proceeding as before, we have <span class="math display">\[
h(X) = \frac{d-2}{\|X\|^2}X \Rightarrow \|h(X)\|^2 = \frac{(d-2)^2}{\|X\|^2},
\]</span> Applying the quotient rule we have <span class="math display">\[Dh(X)_{ii} = (d-2)\frac{\partial}{\partial X_i} \frac{X_i}{\sum_j X_j^2} = (d-2)\frac{\|X\|^2 - 2X_i^2}{\|X\|^4},\]</span> and summing over the coordinates gives <span class="math display">\[\text{tr}(Dh(X)) = (d-2) \frac{d\|X\|^2 - 2\|X\|^2}{\|X\|^4} = -\frac{(d-2)^2}{\|X\|^2}.\]</span> We thereby obtain the estimator <span class="math display">\[
\widehat{\text{MSE}}(X) = d + \frac{(d-2)^2}{\|X\|^2} - 2\frac{(d-2)^2}{\|X\|^2} = d - \frac{(d-2)^2}{\|X\|^2}.
\]</span> Taking expectations, we obtain <span class="math display">\[
\text{MSE}(\theta; \delta_{\text{JS}}) = d - (d-2)^2\EE_\theta\left[\frac{1}{\|X\|^2}\right].
\]</span> Note this is always strictly less than <span class="math inline">\(d\)</span>, which is the MSE of <span class="math inline">\(\delta_0(X) = X\)</span>.</p>
<p>If <span class="math inline">\(\theta = 0\)</span> then <span class="math inline">\(\|X\|^2 \sim \chi_d^2\)</span> and we can apply our previous result to obtain <span class="math display">\[
\text{MSE}(0; \delta_{\text{JS}}) = d - (d-2)^2\frac{1}{d-2} = 2.
\]</span> Thus, even though we are estimating <span class="math inline">\(d\)</span> parameters, our total MSE does not rise with <span class="math inline">\(d\)</span>, because we will shrink harder and harder toward zero the larger <span class="math inline">\(d\)</span> gets. This is fairly remarkable.</p>
<p>On the other hand, suppose <span class="math inline">\(\|\theta\|^2 \to \infty\)</span>. Then <span class="math inline">\(\EE_\theta \|X\|^2 \to \infty\)</span> and the improvement <span class="math inline">\((d-2)^2/\EE_\theta\|X\|^2\)</span> will be driven to <span class="math inline">\(0\)</span>.</p>
<p>Note that, for more general <span class="math inline">\(\sigma^2\)</span>, the James–Stein estimator is <span class="math inline">\(\left(1-\frac{(d-2)\sigma^2}{\|X\|^2}\right)X\)</span>. Then we have <span class="math display">\[h(X) = \sigma^2\frac{d-2}{\|X\|^2} \Rightarrow \|h(X)\|^2 = \sigma^4 \frac{(d-2)^2}{\|X\|^2}, \quad \text{tr} Dh(X) = \sigma^2 \frac{(d-2)^2}{\|X\|^2},\]</span> leading to the estimator <span class="math inline">\(\widehat{\text{MSE}}(X) = \sigma^2 d - \sigma^4\frac{(d-2)^2}{\|X\|^2}\)</span>, and plugging in <span class="math inline">\(\EE_0 1/\|X\|^2 = 1/(d-2)\sigma^2\)</span>, the MSE at <span class="math inline">\(\theta=0\)</span> is <span class="math inline">\(2\sigma^2\)</span>.</p>
<section id="final-thoughts" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="final-thoughts"><span class="header-section-number">3.1</span> Final thoughts</h3>
<p>A few more notes: first, <span class="math inline">\(\delta_{JS}(X)\)</span> also inadmissible, since <span class="math inline">\(\delta_{+}(X) = (1 - \frac{d-2}{\|X\|^2})_+ X\)</span> is strictly better since we never benefit from using a shrinkage parameter <span class="math inline">\(\zeta &gt; 1\)</span>.</p>
<p>A practically more useful version of James–Stein shrinks toward the central value <span class="math inline">\(\overline{X}\)</span>:</p>
<p><span class="math display">\[\delta_{JS+, i}(X) = \overline{X} + (1 - \frac{d-3}{V^2})_+ (X_i - \overline{X})\]</span> This estimator dominates <span class="math inline">\(\delta(X) = X\)</span> for <span class="math inline">\(d \geq 4\)</span>.</p>
<p>Taken to its logical extreme, the James–Stein estimator seems to imply absurd things: should all scientists at Berkeley, across all different fields, pool their estimates to calculate a James–Stein estimator even if their different estimation problems have nothing to do with each other, as long as they are estimating Gaussian location parameters? The overall MSE for all of the estimates really would be better.</p>
<p>To avoid this conclusion we might note that even when the overall MSE is improved, the MSE for a single coordinate can certainly get worse. For example, if <span class="math inline">\(\theta_1 = 10\)</span> but <span class="math inline">\(\theta_2=\theta_3=\cdots=\theta_{1000}=0\)</span>, it’s likely that we’ll overshrink our estimate of <span class="math inline">\(\theta_1\)</span> toward <span class="math inline">\(0\)</span> in order to do well on the other coordinates. So people who believe their estimands are larger than average wouldn’t want to participate in this scheme.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>